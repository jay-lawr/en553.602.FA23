{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88163e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e88163e4",
    "outputId": "b142a787-620d-40ab-e20b-03ab597be1bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tmdbv3api\n",
      "  Downloading tmdbv3api-1.9.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tmdbv3api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tmdbv3api) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tmdbv3api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tmdbv3api) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tmdbv3api) (2023.7.22)\n",
      "Installing collected packages: tmdbv3api\n",
      "Successfully installed tmdbv3api-1.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tmdbv3api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4979ed9c",
   "metadata": {
    "id": "4979ed9c"
   },
   "outputs": [],
   "source": [
    "from tmdbv3api import TMDb\n",
    "from tmdbv3api import Movie\n",
    "from tmdbv3api.exceptions import TMDbException\n",
    "import random\n",
    "import pandas as pd\n",
    "import csv\n",
    "tmdb=TMDb()\n",
    "tmdb.api_key='9cf68f4c97c8f0cc6bb9646da389a808'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d28106",
   "metadata": {
    "id": "38d28106"
   },
   "outputs": [],
   "source": [
    "from tmdbv3api import TMDb, Movie\n",
    "import pandas as pd\n",
    "tmdb=TMDb()\n",
    "tmdb.language='en'\n",
    "movie=Movie()\n",
    "num_movies=0\n",
    "i=1\n",
    "csv_file_path='movie_release_date_revenue_nonzero_ids.csv'\n",
    "#Create a list to store movie IDs\n",
    "movie_data=[]\n",
    "imdb_ids = []\n",
    "wikidata_ids = []\n",
    "#facebook_ids = []\n",
    "#instagram_ids = []\n",
    "#twitter_ids = []\n",
    "#Make a set of IDs to check against\n",
    "written_movie_ids=set()\n",
    "with open(csv_file_path,'r') as csv_file:\n",
    "    csv_reader=csv.reader(csv_file)\n",
    "    next(csv_reader)  #Skip the header row\n",
    "    #Loop until the end of the CSV\n",
    "    while True:\n",
    "        try:\n",
    "            row=next(csv_reader)\n",
    "            movie_id=int(row[1])\n",
    "            #Query movie details by ID\n",
    "            ext_ids=movie.external_ids(movie_id)\n",
    "            if ext_ids:\n",
    "                #print(ext_ids)\n",
    "                movie_data.append(movie_id)\n",
    "                imdb_ids.append(ext_ids.get('imdb_id'))\n",
    "                wikidata_ids.append(ext_ids.get('wikidata_id'))\n",
    "                #facebook_ids.append(ext_ids.get('facebook_id'))\n",
    "                #instagram_ids.append(ext_ids.get('instagram_id'))\n",
    "                #twitter_ids.append(ext_ids.get('twitter_id'))\n",
    "                num_movies += 1\n",
    "                if num_movies%10 == 0:\n",
    "                    print(num_movies)\n",
    "\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            #Handle any exceptions\n",
    "            print(f\"Error processing movie ID {movie_id}:{e}\")\n",
    "ext_ids_df = pd.DataFrame({'ID':movie_data, 'imdb_id': imdb_ids, 'wikidata_id': wikidata_ids})\n",
    "#Create a DataFrame from the movie_data list\n",
    "#df=pd.DataFrame({'ID': movie_data})\n",
    "#Add an index column\n",
    "#ext_ids_df.insert(0,'Index',range(1, len(ext_ids_df) + 1))\n",
    "#Save\n",
    "file_name='movie_external_ids.csv'\n",
    "ext_ids_df.to_csv(file_name,index=False)\n",
    "print(f\"Operation Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R7TL3xUH5uUP",
   "metadata": {
    "id": "R7TL3xUH5uUP"
   },
   "source": [
    "Pull credits:\n",
    "1. go through all movies and get credits\n",
    "2. get ids for each actor in the movie\n",
    "3. if actor is not in actors list, add to actors list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2qMV64hU5Wym",
   "metadata": {
    "id": "2qMV64hU5Wym"
   },
   "outputs": [],
   "source": [
    "num_movies=0\n",
    "\n",
    "csv_file_path='movie_release_date_revenue_nonzero_ids.csv'\n",
    "people_info = pd.DataFrame(columns=['id', 'name', 'known_for_dept', 'popularity'])\n",
    "movie_credits_df = pd.DataFrame(columns=['movie_id', 'cast_ids', 'order', 'director_ids'])\n",
    "#movie_directors_df = pd.DataFrame(columns=['movie_id', 'directors_ids'])\n",
    "\n",
    "with open(csv_file_path,'r') as csv_file:\n",
    "    csv_reader=csv.reader(csv_file)\n",
    "    next(csv_reader)  #Skip the header row\n",
    "    #Loop until the end of the CSV\n",
    "    while True:\n",
    "        try:\n",
    "            row=next(csv_reader)\n",
    "            movie_id=int(row[1])\n",
    "            credits=movie.credits(movie_id)\n",
    "            if credits:\n",
    "                cast = credits.get('cast')\n",
    "                cast_ids = []\n",
    "                order = []\n",
    "                for person in cast:\n",
    "                    person_id = person.get('id')\n",
    "                    cast_ids.append(person_id)\n",
    "                    order.append(person.get('order'))\n",
    "                    # if person not in people dataframe, add them\n",
    "                    if person_id not in people_info.loc[:,'id'].values:\n",
    "                        person_name = person.get('name')\n",
    "                        person_known = person.get('known_for_department')\n",
    "                        person_pop = person.get('popularity')\n",
    "                        people_info = pd.concat([people_info, pd.DataFrame({'id': [person_id], 'name': [person_name], 'known_for_dept': [person_known], 'popularity': [person_pop]})], ignore_index=True)\n",
    "                crew = credits.get('crew')\n",
    "                director_ids = []\n",
    "                for person in crew:\n",
    "                    if person.get('job') == 'Director':\n",
    "                        person_id = person.get('id')\n",
    "                        director_ids.append(person_id)\n",
    "                        if person_id not in people_info.loc[:,'id'].values:\n",
    "                            person_name = person.get('name')\n",
    "                            person_known = person.get('known_for_department')\n",
    "                            person_pop = person.get('popularity')\n",
    "                            people_info = pd.concat([people_info, pd.DataFrame({'id': [person_id], 'name': [person_name], 'known_for_dept': [person_known], 'popularity': [person_pop]})], ignore_index=True)\n",
    "                movie_credits_df = pd.concat([movie_credits_df, pd.DataFrame({'movie_id': [movie_id], 'cast_ids': [cast_ids], 'order': [order], 'director_ids': [director_ids]})], ignore_index=True)\n",
    "            num_movies += 1\n",
    "            if num_movies%10==0:\n",
    "                print(num_movies)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            #Handle any exceptions\n",
    "            print(f\"Error processing movie ID {movie_id}:{e}\")\n",
    "\n",
    "file_name='movie_credits.csv'\n",
    "movie_credits_df.to_csv(file_name,index=False)\n",
    "\n",
    "print(f\"Operation Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "KzK8JfVrF3PU",
   "metadata": {
    "id": "KzK8JfVrF3PU"
   },
   "outputs": [],
   "source": [
    "people_info.to_csv('people_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85d672-b600-4a12-bad9-8e58ff574be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LUCAS UPDATE: Get Credits for 2010, 2011-2012 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b54c62b-c218-4cd3-829c-1d3ca92bb4d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'clean_2010_2012_merged.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m movie_credits_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcast_ids\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirector_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#movie_directors_df = pd.DataFrame(columns=['movie_id', 'directors_ids'])\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_2010_2012_merged.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csv_file:\n\u001b[1;32m     10\u001b[0m     csv_reader\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mreader(csv_file)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mnext\u001b[39m(csv_reader)  \u001b[38;5;66;03m#Skip the header row\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'clean_2010_2012_merged.csv'"
     ]
    }
   ],
   "source": [
    "num_movies=0\n",
    "from tmdbv3api import TMDb, Movie\n",
    "import pandas as pd\n",
    "csv_file_path='clean_2010_2012_merged.csv'\n",
    "people_info = pd.DataFrame(columns=['id', 'name', 'known_for_dept', 'popularity'])\n",
    "movie_credits_df = pd.DataFrame(columns=['movie_id', 'cast_ids', 'order', 'director_ids'])\n",
    "#movie_directors_df = pd.DataFrame(columns=['movie_id', 'directors_ids'])\n",
    "\n",
    "with open('clean_2010_2012_merged.csv','r') as csv_file:\n",
    "    csv_reader=csv.reader(csv_file)\n",
    "    next(csv_reader)  #Skip the header row\n",
    "    #Loop until the end of the CSV\n",
    "    while True:\n",
    "        try:\n",
    "            row=next(csv_reader)\n",
    "            movie_id=int(row[1])\n",
    "            credits=movie.credits(movie_id)\n",
    "            if credits:\n",
    "                cast = credits.get('cast')\n",
    "                cast_ids = []\n",
    "                order = []\n",
    "                for person in cast:\n",
    "                    person_id = person.get('id')\n",
    "                    cast_ids.append(person_id)\n",
    "                    order.append(person.get('order'))\n",
    "                    # if person not in people dataframe, add them\n",
    "                    if person_id not in people_info.loc[:,'id'].values:\n",
    "                        person_name = person.get('name')\n",
    "                        person_known = person.get('known_for_department')\n",
    "                        person_pop = person.get('popularity')\n",
    "                        people_info = pd.concat([people_info, pd.DataFrame({'id': [person_id], 'name': [person_name], 'known_for_dept': [person_known], 'popularity': [person_pop]})], ignore_index=True)\n",
    "                crew = credits.get('crew')\n",
    "                director_ids = []\n",
    "                for person in crew:\n",
    "                    if person.get('job') == 'Director':\n",
    "                        person_id = person.get('id')\n",
    "                        director_ids.append(person_id)\n",
    "                        if person_id not in people_info.loc[:,'id'].values:\n",
    "                            person_name = person.get('name')\n",
    "                            person_known = person.get('known_for_department')\n",
    "                            person_pop = person.get('popularity')\n",
    "                            people_info = pd.concat([people_info, pd.DataFrame({'id': [person_id], 'name': [person_name], 'known_for_dept': [person_known], 'popularity': [person_pop]})], ignore_index=True)\n",
    "                movie_credits_df = pd.concat([movie_credits_df, pd.DataFrame({'movie_id': [movie_id], 'cast_ids': [cast_ids], 'order': [order], 'director_ids': [director_ids]})], ignore_index=True)\n",
    "            num_movies += 1\n",
    "            if num_movies%10==0:\n",
    "                print(num_movies)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            #Handle any exceptions\n",
    "            print(f\"Error processing movie ID {movie_id}:{e}\")\n",
    "\n",
    "file_name='2010_2012_movie_credits.csv'\n",
    "movie_credits_df.to_csv(file_name,index=False)\n",
    "print(f\"Operation Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630a60c-350b-4a8b-8a30-ec7de16011bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
