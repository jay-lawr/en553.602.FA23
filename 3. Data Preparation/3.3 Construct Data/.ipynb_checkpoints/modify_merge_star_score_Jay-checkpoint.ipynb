{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c5a63a",
   "metadata": {},
   "source": [
    "This code is designed to merge the credits dataframe and the tmdb details dataframe into a dataframe called merged_movie_details_credits.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88163e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tmdbv3api in c:\\users\\xylop\\anaconda3\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\xylop\\anaconda3\\lib\\site-packages (from tmdbv3api) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\xylop\\anaconda3\\lib\\site-packages (from requests->tmdbv3api) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\xylop\\anaconda3\\lib\\site-packages (from requests->tmdbv3api) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\xylop\\anaconda3\\lib\\site-packages (from requests->tmdbv3api) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\xylop\\anaconda3\\lib\\site-packages (from requests->tmdbv3api) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install tmdbv3api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4979ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmdbv3api import TMDb\n",
    "from tmdbv3api import Movie\n",
    "from tmdbv3api.exceptions import TMDbException\n",
    "import random\n",
    "import pandas as pd\n",
    "import csv\n",
    "tmdb=TMDb()\n",
    "tmdb.api_key='9cf68f4c97c8f0cc6bb9646da389a808'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc8308",
   "metadata": {},
   "source": [
    ">The next cell will fetch the actor's star score in the year of the movie's release by their id and apply the predefined weighting function to modify the star score based on the billing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1abd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_star_scores(billing_order,star_score):\n",
    "    # Define the shape parameters\n",
    "    X_0 = 4\n",
    "    k = 1.5\n",
    "    Z = k * (billing_order - X_0)\n",
    "    # Calculate the star score using the logistic function (can be modified)\n",
    "    mod = 1 - 1 / (1 + np.exp(-Z))\n",
    "    star_score_mod=star_score*mod\n",
    "    return star_score_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a0a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from math import exp\n",
    "\n",
    "# Initialize csv file paths\n",
    "csv_file_path1='people_info_star_scores_merged.csv' \n",
    "csv_file_path2='clean_merged_data_with_2011_2012.csv'  \n",
    "# Create DataFrames from both CSV files\n",
    "df1 = pd.read_csv(csv_file_path1)\n",
    "df2 = pd.read_csv(csv_file_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5140e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "star_scores = []  # Create a list to collect star scores\n",
    "for index, row in df2.iterrows():\n",
    "    row_cast_info = row['cast_ids']  # Extract cast_ids array\n",
    "    if not pd.isna(row_cast_info):  # Check NaN\n",
    "        row_cast_info = ast.literal_eval(row_cast_info)\n",
    "    else:\n",
    "        row_cast_info = []  # Set to an empty list if NaN\n",
    "    star_scores_row = []\n",
    "    for cast_id in row_cast_info:\n",
    "        release_date = row['Release Year']\n",
    "        star_column_name = f'star_{release_date}'  # Create the corresponding column name\n",
    "        cast_info_row = df1[df1['id'] == cast_id]  # Get the row containing queried cast id\n",
    "        while star_column_name not in cast_info_row and release_date > df['Release Year'].min():\n",
    "            release_date -= 1\n",
    "            star_column_name = f'star_{release_date}'  # Try the previous year\n",
    "        star_score = cast_info_row[star_column_name].values[0] if star_column_name in cast_info_row else None # Use the current year if previous isn't available\n",
    "        star_scores_row.append(star_score)\n",
    "    star_scores_mod = []  # Initialize star scores (modifeid)\n",
    "    for index, star_score in enumerate(star_scores_row):\n",
    "        billing_order = index + 1  # Index starts from 0 but the equation needs it to start from 1\n",
    "        if star_score is not None:\n",
    "            star_score_mod = calculate_star_scores(billing_order, star_score)  # Apply the above function to the star score\n",
    "            star_scores_mod.append(star_score_mod)\n",
    "        else:\n",
    "            star_scores_mod.append(None)  # If no star rating is available for the cast, set to none\n",
    "\n",
    "    star_scores.append(star_scores_mod)  # Append that row array to a singular entry in the corresponding row in df2\n",
    "\n",
    "# Create an output dataframe\n",
    "df_output = df2\n",
    "df_output['star_scores'] = star_scores\n",
    "\n",
    "# Save to csv\n",
    "df_output.to_csv('merged_data_mod_star_score.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588f159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
